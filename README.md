# Praktikum1_HDFS
# Praktikum2,3,4 ğŸ•“ placeholder
# ğŸš€ Hadoop HDFS & YARN â€“ Praktikum Big Data

Praktikum ini membahas instalasi dan konfigurasi **Hadoop Distributed File System (HDFS)** serta **YARN** menggunakan Docker Container.
Hasil akhirnya: sistem Hadoop berhasil berjalan dan dapat diakses melalui browser di `localhost:9870` dan `localhost:8088`.

---

## ğŸ‘©â€ğŸ’» Identitas Mahasiswa

| Nama                    | Kelas    | Mata Kuliah | Dosen Pengampu               |
| ----------------------- | -------- | ----------- | --------------               |
| **Dede Syifa Sifriani** | TI.23.C3 | Big Data    | Agung Nugroho, S.Kom., M.Kom |

---

## ğŸ§  Tujuan

* Memahami konsep penyimpanan data terdistribusi pada Hadoop.
* Melakukan instalasi Hadoop di lingkungan container.
* Menjalankan dan memverifikasi **HDFS** serta **YARN**.
* Mengakses antarmuka web Hadoop.

---

## âš™ï¸ Teknologi yang Digunakan

| Komponen                                      | Keterangan                         |
| --------------------------------------------- | ---------------------------------- |
| ğŸ³ **Docker**                                 | Menjalankan Hadoop dalam container |
| â˜• **OpenJDK 8**                               | Java environment untuk Hadoop      |
| ğŸ—‚ï¸ **HDFS (Hadoop Distributed File System)** | Sistem file terdistribusi          |
| ğŸ”„ **YARN (Yet Another Resource Negotiator)** | Pengatur resource dan job          |
| ğŸ’» **Host OS**                                | Windows 10 + WSL2 Ubuntu           |

---

## ğŸ§© Langkah-Langkah Praktikum

### 1ï¸âƒ£ Jalankan Docker dan Pull Image Hadoop

```bash
docker pull bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
```

### 2ï¸âƒ£ Buat dan Jalankan Container

```bash
docker run -it -p 9870:9870 -p 8088:8088 --name hadoop-single bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8 bash
```

### 3ï¸âƒ£ Aktifkan SSH di Container

```bash
apt-get update
apt-get install -y openssh-server openssh-client
service ssh start
```

### 4ï¸âƒ£ Tambahkan Environment Variable di `~/.bashrc`

```bash
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
```

Lalu jalankan:

```bash
source ~/.bashrc
```

### 5ï¸âƒ£ Format HDFS

```bash
hdfs namenode -format
```

### 6ï¸âƒ£ Jalankan HDFS & YARN

```bash
start-dfs.sh
start-yarn.sh
```

### 7ï¸âƒ£ Cek Proses Hadoop Aktif

```bash
jps
```

Hasil yang diharapkan:

```
NameNode
DataNode
SecondaryNameNode
ResourceManager
Jps
```

---

## ğŸŒ Akses Web UI

| Komponen                       | URL                                            | Fungsi                   |
| ------------------------------ | ---------------------------------------------- | ------------------------ |
| ğŸ—‚ï¸ **HDFS NameNode UI**       | [http://localhost:9870](http://localhost:9870) | Monitoring status HDFS   |
| ğŸ”„ **YARN ResourceManager UI** | [http://localhost:8088](http://localhost:8088) | Monitoring job & cluster |

---

## âš ï¸ Troubleshooting Umum

| Error                                                        | Penyebab                         | Solusi                                                                             |
| ------------------------------------------------------------ | -------------------------------- | ---------------------------------------------------------------------------------- |
| `ssh: connect to host localhost port 22: Connection refused` | SSH belum aktif                  | Jalankan `service ssh start`                                                       |
| `Permission denied (publickey,password)`                     | Belum setup SSH key              | Jalankan `ssh-keygen -t rsa` dan `cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys` |
| `ERROR: Attempting to operate on hdfs namenode as root`      | Variabel user Hadoop belum diset | Tambahkan export di `.bashrc`                                                      |
| `namenode needs formatting`                                  | HDFS belum diformat              | Jalankan `hdfs namenode -format`                                                   |

---

## ğŸ“¸ Hasil Akhir (Tambahkan Screenshot)

1. âœ… Output `jps` menampilkan semua komponen aktif.
2. ğŸŒ Tampilan **HDFS Overview** (`http://localhost:9870/dfshealth.html`).
   ### **Lampiran Bukti berhasil jalankan HDFS**

Berikut adalah *screenshot* dari hasil
![HDFS overview](BUKTI2.png)


3. ğŸŒ Tampilan **YARN Cluster** (`http://localhost:8088/cluster`).
   
Berikut adalah *screenshot* dari hasil
![YARN Cluster](BUKTI1.png)

---

ğŸ•“ Modul 2: YARN dan MapReduce (Belum Selesai)

Status: Sedang dalam tahap konfigurasi ResourceManager dan pembuatan job MapReduce.
ğŸ—“ï¸ Rencana dilanjutkan minggu depan.

ğŸ”œ Modul 3: HBase / Hive

Status: Belum dikerjakan
ğŸ—“ï¸ Akan dikerjakan setelah Modul 2.

ğŸ”œ Modul 4: Pig / Spark

Status: Belum dikerjakan
ğŸ—“ï¸ Target penyelesaian: Akhir bulan ini.

## ğŸ§¾ Kesimpulan

* Hadoop berhasil dijalankan dengan **HDFS** dan **YARN** aktif di dalam container Docker.
* Semua service dapat diakses melalui browser.
* Praktikum dinyatakan **berhasil 100%**.

---

## ğŸ“š Referensi

* [Apache Hadoop Documentation](https://hadoop.apache.org)
* [Docker Hadoop â€“ bde2020](https://hub.docker.com/r/bde2020/hadoop-namenode)
* Modul Praktikum Big Data â€“ Universitas Pelita Bangsa (2025)
